{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "import collections\n",
    "import os\n",
    "import shutil\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.基础配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7401"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 固定随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20e00234090>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定程序运行在特定的GPU卡上"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CUDA_VISIBLE_DEVICES=0,1 python train.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor和np.ndarray转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(1,13).reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor=torch.from_numpy(a).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.],\n",
       "       [ 5.,  6.,  7.,  8.],\n",
       "       [ 9., 10., 11., 12.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor和PIL.Image转换"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# torch.Tensor -> PIL.Image.\n",
    "image = PIL.Image.fromarray(torch.clamp(tensor * 255, min=0, max=255\n",
    "    ).byte().permute(1, 2, 0).cpu().numpy())\n",
    "image = torchvision.transforms.functional.to_pil_image(tensor)  #等价方式\n",
    "\n",
    "# PIL.Image -> torch.Tensor.\n",
    "tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))\n",
    "    ).permute(2, 0, 1).float() / 255\n",
    "tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))  # 等价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.ndarray和PIL.Image转换"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# np.ndarray -> PIL.Image.\n",
    "image = PIL.Image.fromarray(ndarray.astypde(np.uint8))\n",
    "\n",
    "# PIL.Image -> np.ndarray.\n",
    "ndarray = np.asarray(PIL.Image.open(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算模型整体参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "    \n",
    "class YOLO_V1(nn.Module):\n",
    "    def __init__(self):\n",
    "        C = 20  # number of classes\n",
    "        super(YOLO_V1, self).__init__()\n",
    "        print(\"\\n------Initiating YOLO v1------\\n\")\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=7//2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=128, kernel_size=1, stride=1, padding=1//2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1, stride=1, padding=1//2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=1//2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=1//2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=1//2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, stride=1, padding=1//2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=1//2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=1//2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=2, padding=3//2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1),\n",
    "        )\n",
    "        self.conv_layer6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=3//2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        self.flatten = Flatten()\n",
    "        self.conn_layer1 = nn.Sequential(\n",
    "            nn.Linear(in_features=7*7*1024, out_features=4096),\n",
    "            nn.Dropout(),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "        self.conn_layer2 = nn.Sequential(nn.Linear(in_features=4096, out_features=7 * 7 * (2 * 5 + C)))\n",
    "\n",
    "    def forward(self, input):\n",
    "        conv_layer1 = self.conv_layer1(input)\n",
    "        conv_layer2 = self.conv_layer2(conv_layer1)\n",
    "        conv_layer3 = self.conv_layer3(conv_layer2)\n",
    "        conv_layer4 = self.conv_layer4(conv_layer3)\n",
    "        conv_layer5 = self.conv_layer5(conv_layer4)\n",
    "        conv_layer6 = self.conv_layer6(conv_layer5)\n",
    "        flatten = self.flatten(conv_layer6)\n",
    "        conn_layer1 = self.conn_layer1(flatten)\n",
    "        output = self.conn_layer2(conn_layer1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------Initiating YOLO v1------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yolov1=YOLO_V1().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 208, 208]           9,472\n",
      "       BatchNorm2d-2         [-1, 64, 208, 208]             128\n",
      "         LeakyReLU-3         [-1, 64, 208, 208]               0\n",
      "         MaxPool2d-4         [-1, 64, 104, 104]               0\n",
      "            Conv2d-5        [-1, 192, 104, 104]         110,784\n",
      "       BatchNorm2d-6        [-1, 192, 104, 104]             384\n",
      "         LeakyReLU-7        [-1, 192, 104, 104]               0\n",
      "         MaxPool2d-8          [-1, 192, 52, 52]               0\n",
      "            Conv2d-9          [-1, 128, 52, 52]          24,704\n",
      "           Conv2d-10          [-1, 256, 52, 52]         295,168\n",
      "           Conv2d-11          [-1, 256, 52, 52]          65,792\n",
      "           Conv2d-12          [-1, 512, 52, 52]       1,180,160\n",
      "      BatchNorm2d-13          [-1, 512, 52, 52]           1,024\n",
      "        LeakyReLU-14          [-1, 512, 52, 52]               0\n",
      "        MaxPool2d-15          [-1, 512, 26, 26]               0\n",
      "           Conv2d-16          [-1, 256, 26, 26]         131,328\n",
      "           Conv2d-17          [-1, 512, 26, 26]       1,180,160\n",
      "           Conv2d-18          [-1, 256, 26, 26]         131,328\n",
      "           Conv2d-19          [-1, 512, 26, 26]       1,180,160\n",
      "           Conv2d-20          [-1, 256, 26, 26]         131,328\n",
      "           Conv2d-21          [-1, 512, 26, 26]       1,180,160\n",
      "           Conv2d-22          [-1, 512, 26, 26]         262,656\n",
      "           Conv2d-23         [-1, 1024, 26, 26]       4,719,616\n",
      "      BatchNorm2d-24         [-1, 1024, 26, 26]           2,048\n",
      "        MaxPool2d-25         [-1, 1024, 13, 13]               0\n",
      "           Conv2d-26          [-1, 512, 13, 13]         524,800\n",
      "           Conv2d-27         [-1, 1024, 13, 13]       4,719,616\n",
      "           Conv2d-28          [-1, 512, 13, 13]         524,800\n",
      "           Conv2d-29         [-1, 1024, 13, 13]       4,719,616\n",
      "           Conv2d-30         [-1, 1024, 13, 13]       9,438,208\n",
      "           Conv2d-31           [-1, 1024, 7, 7]       9,438,208\n",
      "      BatchNorm2d-32           [-1, 1024, 7, 7]           2,048\n",
      "        LeakyReLU-33           [-1, 1024, 7, 7]               0\n",
      "           Conv2d-34           [-1, 1024, 7, 7]       9,438,208\n",
      "           Conv2d-35           [-1, 1024, 7, 7]       9,438,208\n",
      "      BatchNorm2d-36           [-1, 1024, 7, 7]           2,048\n",
      "        LeakyReLU-37           [-1, 1024, 7, 7]               0\n",
      "          Flatten-38                [-1, 50176]               0\n",
      "           Linear-39                 [-1, 4096]     205,524,992\n",
      "          Dropout-40                 [-1, 4096]               0\n",
      "        LeakyReLU-41                 [-1, 4096]               0\n",
      "           Linear-42                 [-1, 1470]       6,022,590\n",
      "================================================================\n",
      "Total params: 270,399,742\n",
      "Trainable params: 270,399,742\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.98\n",
      "Forward/backward pass size (MB): 202.53\n",
      "Params size (MB): 1031.49\n",
      "Estimated Total Size (MB): 1236.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(yolov1,(3,416,416))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloV2(nn.Module):\n",
    "    def __init__(self, num_classes,\n",
    "                 anchors=[(1.3221, 1.73145), (3.19275, 4.00944), (5.05587, 8.09892), (9.47112, 4.84053),\n",
    "                          (11.2364, 10.0071)]):\n",
    "        super(YoloV2, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "\n",
    "        self.stage1_conv1 = nn.Sequential(nn.Conv2d(3, 32, 3, 1, 1, bias=False), nn.BatchNorm2d(32),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True), nn.MaxPool2d(2, 2))\n",
    "        self.stage1_conv2 = nn.Sequential(nn.Conv2d(32, 64, 3, 1, 1, bias=False), nn.BatchNorm2d(64),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True), nn.MaxPool2d(2, 2))\n",
    "        self.stage1_conv3 = nn.Sequential(nn.Conv2d(64, 128, 3, 1, 1, bias=False), nn.BatchNorm2d(128),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv4 = nn.Sequential(nn.Conv2d(128, 64, 1, 1, 0, bias=False), nn.BatchNorm2d(64),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv5 = nn.Sequential(nn.Conv2d(64, 128, 3, 1, 1, bias=False), nn.BatchNorm2d(128),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True), nn.MaxPool2d(2, 2))\n",
    "        self.stage1_conv6 = nn.Sequential(nn.Conv2d(128, 256, 3, 1, 1, bias=False), nn.BatchNorm2d(256),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv7 = nn.Sequential(nn.Conv2d(256, 128, 1, 1, 0, bias=False), nn.BatchNorm2d(128),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv8 = nn.Sequential(nn.Conv2d(128, 256, 3, 1, 1, bias=False), nn.BatchNorm2d(256),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True), nn.MaxPool2d(2, 2))\n",
    "        self.stage1_conv9 = nn.Sequential(nn.Conv2d(256, 512, 3, 1, 1, bias=False), nn.BatchNorm2d(512),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv10 = nn.Sequential(nn.Conv2d(512, 256, 1, 1, 0, bias=False), nn.BatchNorm2d(256),\n",
    "                                           nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv11 = nn.Sequential(nn.Conv2d(256, 512, 3, 1, 1, bias=False), nn.BatchNorm2d(512),\n",
    "                                           nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv12 = nn.Sequential(nn.Conv2d(512, 256, 1, 1, 0, bias=False), nn.BatchNorm2d(256),\n",
    "                                           nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage1_conv13 = nn.Sequential(nn.Conv2d(256, 512, 3, 1, 1, bias=False), nn.BatchNorm2d(512),\n",
    "                                           nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.stage2_a_maxpl = nn.MaxPool2d(2, 2)\n",
    "        self.stage2_a_conv1 = nn.Sequential(nn.Conv2d(512, 1024, 3, 1, 1, bias=False),\n",
    "                                            nn.BatchNorm2d(1024), nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv2 = nn.Sequential(nn.Conv2d(1024, 512, 1, 1, 0, bias=False), nn.BatchNorm2d(512),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv3 = nn.Sequential(nn.Conv2d(512, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv4 = nn.Sequential(nn.Conv2d(1024, 512, 1, 1, 0, bias=False), nn.BatchNorm2d(512),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv5 = nn.Sequential(nn.Conv2d(512, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv6 = nn.Sequential(nn.Conv2d(1024, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage2_a_conv7 = nn.Sequential(nn.Conv2d(1024, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                            nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.stage2_b_conv = nn.Sequential(nn.Conv2d(512, 64, 1, 1, 0, bias=False), nn.BatchNorm2d(64),\n",
    "                                           nn.LeakyReLU(0.1, inplace=True))\n",
    "\n",
    "        self.stage3_conv1 = nn.Sequential(nn.Conv2d(256 + 1024, 1024, 3, 1, 1, bias=False), nn.BatchNorm2d(1024),\n",
    "                                          nn.LeakyReLU(0.1, inplace=True))\n",
    "        self.stage3_conv2 = nn.Conv2d(1024, len(self.anchors) * (5 + num_classes), 1, 1, 0, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.stage1_conv1(input)\n",
    "        output = self.stage1_conv2(output)\n",
    "        output = self.stage1_conv3(output)\n",
    "        output = self.stage1_conv4(output)\n",
    "        output = self.stage1_conv5(output)\n",
    "        output = self.stage1_conv6(output)\n",
    "        output = self.stage1_conv7(output)\n",
    "        output = self.stage1_conv8(output)\n",
    "        output = self.stage1_conv9(output)\n",
    "        output = self.stage1_conv10(output)\n",
    "        output = self.stage1_conv11(output)\n",
    "        output = self.stage1_conv12(output)\n",
    "        output = self.stage1_conv13(output)\n",
    "\n",
    "        residual = output\n",
    "\n",
    "        output_1 = self.stage2_a_maxpl(output)\n",
    "        output_1 = self.stage2_a_conv1(output_1)\n",
    "        output_1 = self.stage2_a_conv2(output_1)\n",
    "        output_1 = self.stage2_a_conv3(output_1)\n",
    "        output_1 = self.stage2_a_conv4(output_1)\n",
    "        output_1 = self.stage2_a_conv5(output_1)\n",
    "        output_1 = self.stage2_a_conv6(output_1)\n",
    "        output_1 = self.stage2_a_conv7(output_1)\n",
    "\n",
    "        output_2 = self.stage2_b_conv(residual)\n",
    "        batch_size, num_channel, height, width = output_2.data.size()\n",
    "        output_2 = output_2.view(batch_size, int(num_channel / 4), height, 2, width, 2).contiguous()\n",
    "        output_2 = output_2.permute(0, 3, 5, 1, 2, 4).contiguous()\n",
    "        output_2 = output_2.view(batch_size, -1, int(height / 2), int(width / 2))\n",
    "\n",
    "        output = torch.cat((output_1, output_2), 1)\n",
    "        output = self.stage3_conv1(output)\n",
    "        output = self.stage3_conv2(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov2=YoloV2(20).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 416, 416]             864\n",
      "       BatchNorm2d-2         [-1, 32, 416, 416]              64\n",
      "         LeakyReLU-3         [-1, 32, 416, 416]               0\n",
      "         MaxPool2d-4         [-1, 32, 208, 208]               0\n",
      "            Conv2d-5         [-1, 64, 208, 208]          18,432\n",
      "       BatchNorm2d-6         [-1, 64, 208, 208]             128\n",
      "         LeakyReLU-7         [-1, 64, 208, 208]               0\n",
      "         MaxPool2d-8         [-1, 64, 104, 104]               0\n",
      "            Conv2d-9        [-1, 128, 104, 104]          73,728\n",
      "      BatchNorm2d-10        [-1, 128, 104, 104]             256\n",
      "        LeakyReLU-11        [-1, 128, 104, 104]               0\n",
      "           Conv2d-12         [-1, 64, 104, 104]           8,192\n",
      "      BatchNorm2d-13         [-1, 64, 104, 104]             128\n",
      "        LeakyReLU-14         [-1, 64, 104, 104]               0\n",
      "           Conv2d-15        [-1, 128, 104, 104]          73,728\n",
      "      BatchNorm2d-16        [-1, 128, 104, 104]             256\n",
      "        LeakyReLU-17        [-1, 128, 104, 104]               0\n",
      "        MaxPool2d-18          [-1, 128, 52, 52]               0\n",
      "           Conv2d-19          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-20          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-21          [-1, 256, 52, 52]               0\n",
      "           Conv2d-22          [-1, 128, 52, 52]          32,768\n",
      "      BatchNorm2d-23          [-1, 128, 52, 52]             256\n",
      "        LeakyReLU-24          [-1, 128, 52, 52]               0\n",
      "           Conv2d-25          [-1, 256, 52, 52]         294,912\n",
      "      BatchNorm2d-26          [-1, 256, 52, 52]             512\n",
      "        LeakyReLU-27          [-1, 256, 52, 52]               0\n",
      "        MaxPool2d-28          [-1, 256, 26, 26]               0\n",
      "           Conv2d-29          [-1, 512, 26, 26]       1,179,648\n",
      "      BatchNorm2d-30          [-1, 512, 26, 26]           1,024\n",
      "        LeakyReLU-31          [-1, 512, 26, 26]               0\n",
      "           Conv2d-32          [-1, 256, 26, 26]         131,072\n",
      "      BatchNorm2d-33          [-1, 256, 26, 26]             512\n",
      "        LeakyReLU-34          [-1, 256, 26, 26]               0\n",
      "           Conv2d-35          [-1, 512, 26, 26]       1,179,648\n",
      "      BatchNorm2d-36          [-1, 512, 26, 26]           1,024\n",
      "        LeakyReLU-37          [-1, 512, 26, 26]               0\n",
      "           Conv2d-38          [-1, 256, 26, 26]         131,072\n",
      "      BatchNorm2d-39          [-1, 256, 26, 26]             512\n",
      "        LeakyReLU-40          [-1, 256, 26, 26]               0\n",
      "           Conv2d-41          [-1, 512, 26, 26]       1,179,648\n",
      "      BatchNorm2d-42          [-1, 512, 26, 26]           1,024\n",
      "        LeakyReLU-43          [-1, 512, 26, 26]               0\n",
      "        MaxPool2d-44          [-1, 512, 13, 13]               0\n",
      "           Conv2d-45         [-1, 1024, 13, 13]       4,718,592\n",
      "      BatchNorm2d-46         [-1, 1024, 13, 13]           2,048\n",
      "        LeakyReLU-47         [-1, 1024, 13, 13]               0\n",
      "           Conv2d-48          [-1, 512, 13, 13]         524,288\n",
      "      BatchNorm2d-49          [-1, 512, 13, 13]           1,024\n",
      "        LeakyReLU-50          [-1, 512, 13, 13]               0\n",
      "           Conv2d-51         [-1, 1024, 13, 13]       4,718,592\n",
      "      BatchNorm2d-52         [-1, 1024, 13, 13]           2,048\n",
      "        LeakyReLU-53         [-1, 1024, 13, 13]               0\n",
      "           Conv2d-54          [-1, 512, 13, 13]         524,288\n",
      "      BatchNorm2d-55          [-1, 512, 13, 13]           1,024\n",
      "        LeakyReLU-56          [-1, 512, 13, 13]               0\n",
      "           Conv2d-57         [-1, 1024, 13, 13]       4,718,592\n",
      "      BatchNorm2d-58         [-1, 1024, 13, 13]           2,048\n",
      "        LeakyReLU-59         [-1, 1024, 13, 13]               0\n",
      "           Conv2d-60         [-1, 1024, 13, 13]       9,437,184\n",
      "      BatchNorm2d-61         [-1, 1024, 13, 13]           2,048\n",
      "        LeakyReLU-62         [-1, 1024, 13, 13]               0\n",
      "           Conv2d-63         [-1, 1024, 13, 13]       9,437,184\n",
      "      BatchNorm2d-64         [-1, 1024, 13, 13]           2,048\n",
      "        LeakyReLU-65         [-1, 1024, 13, 13]               0\n",
      "           Conv2d-66           [-1, 64, 26, 26]          32,768\n",
      "      BatchNorm2d-67           [-1, 64, 26, 26]             128\n",
      "        LeakyReLU-68           [-1, 64, 26, 26]               0\n",
      "           Conv2d-69         [-1, 1024, 13, 13]      11,796,480\n",
      "      BatchNorm2d-70         [-1, 1024, 13, 13]           2,048\n",
      "        LeakyReLU-71         [-1, 1024, 13, 13]               0\n",
      "           Conv2d-72          [-1, 125, 13, 13]         128,000\n",
      "================================================================\n",
      "Total params: 50,655,264\n",
      "Trainable params: 50,655,264\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.98\n",
      "Forward/backward pass size (MB): 389.98\n",
      "Params size (MB): 193.23\n",
      "Estimated Total Size (MB): 585.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(yolov2,(3,416,416))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型权值初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in yolov1.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',\n",
    "                                      nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(layer.weight, val=1.0)\n",
    "        torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部分层使用预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decom_vgg16():\n",
    "    # the 30th layer of features is relu of conv5_3\n",
    "    model = torchvision.models.vgg16(pretrained=False)\n",
    "    features = list(model.features)[:30]\n",
    "    classifier = model.classifier\n",
    "\n",
    "    classifier = list(classifier)\n",
    "    del classifier[6]\n",
    "    classifier = nn.Sequential(*classifier)\n",
    "\n",
    "    # freeze top4 conv\n",
    "    for layer in features[:10]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    return nn.Sequential(*features), classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features,classifier=decom_vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixup"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for images, labels in train_loader:\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "    # Mixup images.\n",
    "    lambda_ = np.random.beta(alpha, alpha)\n",
    "    index = torch.randperm(images.size(0)).cuda()\n",
    "    mixed_images = lambda_ * images + (1 - lambda_) * images[index, :]\n",
    "\n",
    "    # Mixup loss.    \n",
    "    scores = model(mixed_images)\n",
    "    loss = (lambda_ * loss_function(scores, labels) \n",
    "            + (1 - lambda_) * loss_function(scores, labels))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
